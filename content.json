[{"title":"Pandas: Read and Write Files","slug":"Pandas-Read-and-Write-Files","date":"2023-11-01T15:05:20.000Z","updated":"2023-11-01T15:44:17.403Z","comments":true,"path":"2023/11/01/Pandas-Read-and-Write-Files/","link":"","permalink":"http://example.com/2023/11/01/Pandas-Read-and-Write-Files/","excerpt":"","text":"Preparing DataSheet_1 中文名称 英文名称 AD 安道尔 Andorra AE 阿联酋 United Arab Emirates AF 阿富汗 Afghanistan AG 安提瓜和巴布达 Antigua and Barbuda AI 安圭拉 Anguilla AL 阿尔巴尼亚 Albania AM 亚美尼亚 Armenia AN 荷属安的列斯 Netherlands Antilles AO 安哥拉 Angola AQ 南极洲 Antarctica AR 阿根廷 Argentina AS 美属萨摩亚 American Samoa AT 奥地利 Austria AU 澳大利亚 Australia AW 阿鲁巴 Aruba AZ 阿塞拜疆 Azerbaijan BA 波斯尼亚和黑塞哥维那 Bosnia and Herzegovina BB 巴巴多斯 Barbados BD 孟加拉国 Bangladesh BE 比利时 Belgium BF 布基纳法索 Burkina Faso BG 保加利亚 Bulgaria BH 巴林 Bahrain BI 布隆迪 Burundi BJ 贝宁 Benin BM 百慕大 Bermuda BN 文莱 Brunei Darussalam BO 玻利维亚 Bolivia BR 巴西 Brazil BS 巴哈马 Bahamas Sheet_2 Head1 Head2 Test1 Test2 Python 1234567data = &#123; &#x27;AD&#x27;:&#123;&#x27;中文名称&#x27;:&#x27;安道尔&#x27;, &#x27;英文名称&#x27;:&#x27;Andorra&#x27;&#125;, &#x27;AE&#x27;:&#123;&#x27;中文名称&#x27;:&#x27;阿联酋&#x27;, &#x27;英文名称&#x27;:&#x27;United Arab Emirates&#x27;&#125;, ... ... ...&#125; 1234import pandas as pddf = pd.DataFrame(data=data.T)print(&#x27;df&#x27;) 12345678 中文名称 英文名称代码 AD 安道尔 Andorra AE 阿联酋 United Arab Emirates AF 阿富汗 Afghanistan AG 安提瓜和巴布达 Antigua and Barbuda AI 安圭拉 Anguilla.. ... ... Write a CSV File .to_csv(): 1df.to_csv(&#x27;data.csv&#x27;) Read a CSV File .read_csv(): 1df = pd.read_csv(&#x27;data.csv&#x27;, index_col=0) Using pandas to Write and Read Excel Files xlwt to write to .xls files openpyxl or XlsxWriter to write to .xlsx files xlrd to read Excel files 1pip install xlwt openpyxl xlsxwriter xlrd Write an Excel File1df.to_excel(&#x27;data.xlsx&#x27;) Read an Excel File Read_excel(): 1df = pd.read_excel(&#x27;data.xlsx&#x27;, index_col=0)","categories":[],"tags":[{"name":"Pandas","slug":"Pandas","permalink":"http://example.com/tags/Pandas/"},{"name":"CSV","slug":"CSV","permalink":"http://example.com/tags/CSV/"},{"name":"Excel","slug":"Excel","permalink":"http://example.com/tags/Excel/"},{"name":"Read","slug":"Read","permalink":"http://example.com/tags/Read/"},{"name":"Write","slug":"Write","permalink":"http://example.com/tags/Write/"}]},{"title":"Snellius","slug":"Snellius","date":"2023-10-29T11:26:00.000Z","updated":"2023-10-29T20:03:37.884Z","comments":true,"path":"2023/10/29/Snellius/","link":"","permalink":"http://example.com/2023/10/29/Snellius/","excerpt":"","text":"AppleOpen the ‘Terminal’ application. In the terminal window, type 1ssh &lt;username&gt;@snellius.surf.nl To redirect any graphic output from the HPC system to your own system, you’ll need a X-server like XQuartz. Then, log in to the HPC system using. 1ssh -X &lt;username&gt;@snellius.surf.nl Manual use of minicondaStep 1: Get Miniconda 1wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.10.3-Linux-x86_64.sh Step 2: Install Miniconda (“-b” skips all confirmations with “yes”) 1bash Miniconda3-py37_4.10.3-Linux-x86_64.sh -b Initialize conda. 1~/miniconda3/bin/conda init Close the current terminal and start a new one. Check that conda has been installed: the shell prompt should start with the name of the currently active conda-environment. By default, this is “(base)”. Try the version parameter. 12(base) username@hostname:~$ conda --versionconda 4.10.3 The actual version, of course, can differ. Update conda. 1conda update conda -y Step 3: Create a virtual conda-environment 1conda create --yes --name 01_pandas1.3 pandas=1.3.0 Step 4: Activate the environment 1conda activate 01_pandas1.3 Step 5: Create a kernel from the environment If you want to use your environment as a Jupyter-kernel, you can continue with this step. Install the ipykernel tool into the environment. 1conda ``install` `--``yes` `--channel anaconda ipykernel Run the ipykernel tool. The display name will identify your environment/kernel in Jupyter Notebooks. 1python3 -m ipykernel ``install` `--user --name 01_pandas1.3 --display-name ``&quot;Py Pandas 1.3&quot; You can now leave the environment again. 1conda deactivate Snellius partitionsCompute nodes are grouped into partitions in order to allow the user to select different hardware to run their software on. Each partition includes a subset of nodes with a different type of hardware and a specific maximum wall time. The partitions can be selected by users via the SLURM option: 1#SBATCH --partition=&lt;partition name&gt; or 1#SBATCH -p &lt;partition name&gt; The partitions available on Snellius are summarised in the table. For details of the different hardware available on each node, please look at the Snellius hardware and file systems page. Getting account and budget informationYou can view your account details using 1$ accinfo This shows information such as the e-mail associated with the account, the initial and remaining budget, and until when the account is valid. An overview of the SBU consumption for the current account can be obtained with 1$ accuse By default, consumption is shown for the current login, per month, over the last year. Per day usage can be obtained by adding the -d flag. The start and end of the period shown in the overview can be changed with the -s DD-MM-YYYYand -e DD-MM-YYYY flags, respectively. Finally, consumption for a specific account or login can be obtained using -a accountname and -u username, respectively. In case you want to know the CPU/GPU budgets separately, you can try: 1accinfo --product=cpu``accinfo --product=gpu SLURM batch systemDefining the requirements of a job For the batch system to know which nodes to allocate to you, and for how long, you need to start your jobscript by defining options for the SLURM batch system. The SLURM system will read all lines from the start of your job script until the first non-comment or empty line that does not start #SBATCH - hence all your SLURM options should be at the start of your job script, before anything else. Shell You can define the interpreter for your job script with a shebang), just like in any other script. For example, if you want to use Bash, you should start your script with 1#!/bin/bash Wall clock time You can set the duration for which the nodes remain allocated to you (known as the wall clock time), using 1#SBATCH -t ``1``:``30``:``00 The duration can be specified in minutes, or in the MM:SS, or HH:MM:SS format (as in the example), of on the D-HH:MM:SS. In general, the maximum walltime for CPU jobs is 120 hours (5 days); for jobs submitted to the GPU queue, the maximum walltime is 120 hours. Some queues have a different maximum walltime. Choose your wall clock time carefully: if your job is still running after the wall clock time has exceeded, it will be cancelled and you will lose your results! In general, we recommend timing a minimal version of your computational task in order to estimate how long the total task will take. Then, choose your wall clock time liberally based on your expected runtime (e.g. 1.5-2x higher). Once you gain more experience in running similar-sized jobs, you could consider setting walltimes more accurately, as shorter jobs are slightly easier for the scheduler to fit in. Partition On our systems, different types of node are grouped into partitions each having different limit for wall-clock time, job size, access limitation, etc. Partitions can overlap, i.e. compute nodes can be contained in several partitions (e.g.: “normal” and “short” partitions share a large number of nodes but they have different maximum wall time limit). Users can therefore request specific a node type by submitting to the partition which contain it (from the one available on each system). To set the partition you want to submit to, use the -p argument. For example to run on the thin partition (available on Snellius) you would need to specify: 1#SBATCH -p thin If you don’t specify a partition, your job will be scheduled on the thin partition by default. You can check all available partitions, including their maximum walltime and number of nodes, using the sinfo command. The available compute partitions that batch jobs can be submitted to can be listed by issuing the following command 1sinfo You can get a summary of the available partitions by using the -s flag. 1sinfo -s The available partitions of Snellius are described here.","categories":[],"tags":[{"name":"Connecting","slug":"Connecting","permalink":"http://example.com/tags/Connecting/"},{"name":"Transferring Data","slug":"Transferring-Data","permalink":"http://example.com/tags/Transferring-Data/"},{"name":"SURF","slug":"SURF","permalink":"http://example.com/tags/SURF/"},{"name":"Snellius","slug":"Snellius","permalink":"http://example.com/tags/Snellius/"}]},{"title":"Measurement of Data Discreteness","slug":"Measurement-of-Data-Discreteness","date":"2023-10-22T20:19:49.000Z","updated":"2023-10-22T21:45:18.207Z","comments":true,"path":"2023/10/22/Measurement-of-Data-Discreteness/","link":"","permalink":"http://example.com/2023/10/22/Measurement-of-Data-Discreteness/","excerpt":"","text":"The discreteness of data measures how spread out a set of data is. There are many standards and methods to measure this spread, and the choice of a specific method depends on the specific data requirements. Range (极差)It’s the most simple one among all the methods. It reflects the range of samples. R = max(i) - min(i)Interquartile (IQR, 四分位差)IQR represents the range between the 75th percentile data (Q3) and the 25th percentile data (Q1) in the dataset. It reflects the range of the central 50% of the data. IQR = Q_3 - Q_1Mean Deviation (平均差)The sum of absolute differences between each variable value and the mean, divided by the total count n, the mean deviation with the mean as the center, comprehensively and accurately reflects the discreteness of a dataset. M_d = \\frac{\\sum_{i=1}^{n}|x_n-\\bar{x}|}{n}Variance/Standard Deviation/Coefficient of Variation (方差/标准差/离散系数) Variance = \\frac{1}{N}\\sum_{i=1}^n(x_i-\\bar{x})^2 Standard Deviation = \\sqrt{Variance} V_i = \\frac{StandardDeviation}{\\bar{x}} 12345678910111213141516171819202122232425import numpy as npimport stats as stsscores = [31, 24, 23, 25, 14, 25, 13, 12, 14, 23, 32, 34, 43, 41, 21, 23, 26, 26, 34, 42, 43, 25, 24, 23, 24, 44, 23, 14, 52,32, 42, 44, 35, 28, 17, 21, 32, 42, 12, 34]# Measures of Cnetral Tendency集中趋势的度量print(&#x27;Sum/求和：&#x27;,np.sum(scores))print(&#x27;Count/个数：&#x27;,len(scores))print(&#x27;Mean/平均值:&#x27;,np.mean(scores))print(&#x27;Median/中位数:&#x27;,np.median(scores))print(&#x27;Mode众数:&#x27;,sts.mode(scores))print(&#x27;Lower Quartile/上四分位数&#x27;,sts.quantile(scores,p=0.25))print(&#x27;Upper Quartile/下四分位数&#x27;,sts.quantile(scores,p=0.75))# Measures of Dispersion离散趋势的度量print(&#x27;Maximum/最大值:&#x27;,np.max(scores))print(&#x27;Minimum/最小值:&#x27;,np.min(scores))print(&#x27;Rnage/极差:&#x27;,np.max(scores)-np.min(scores))print(&#x27;Interquartile Range/四分位差&#x27;,sts.quantile(scores,p=0.75)-sts.quantile(scores,p=0.25))print(&#x27;Standard Deviation/标准差:&#x27;,np.std(scores))print(&#x27;Variance/方差:&#x27;,np.var(scores))print(&#x27;Coefficient of Variation/离散系数:&#x27;,np.std(scores)/np.mean(scores))# Measuers of Skewness and Kurtosis偏度与峰度的度量print(&#x27;Skewness/偏度:&#x27;,sts.skewness(scores))print(&#x27;Kurtosis/峰度:&#x27;,sts.kurtosis(scores))&lt;/span&gt;","categories":[],"tags":[{"name":"Dispersion","slug":"Dispersion","permalink":"http://example.com/tags/Dispersion/"},{"name":"Discreteness","slug":"Discreteness","permalink":"http://example.com/tags/Discreteness/"},{"name":"Range","slug":"Range","permalink":"http://example.com/tags/Range/"},{"name":"Mean Deviation","slug":"Mean-Deviation","permalink":"http://example.com/tags/Mean-Deviation/"},{"name":"Standard Deviation","slug":"Standard-Deviation","permalink":"http://example.com/tags/Standard-Deviation/"},{"name":"Variance","slug":"Variance","permalink":"http://example.com/tags/Variance/"},{"name":"Interquartile","slug":"Interquartile","permalink":"http://example.com/tags/Interquartile/"},{"name":"IQR","slug":"IQR","permalink":"http://example.com/tags/IQR/"},{"name":"Heteroscedasticity Ratio","slug":"Heteroscedasticity-Ratio","permalink":"http://example.com/tags/Heteroscedasticity-Ratio/"},{"name":"Coefficient of Variation","slug":"Coefficient-of-Variation","permalink":"http://example.com/tags/Coefficient-of-Variation/"}]},{"title":"My Profile","slug":"My-Profile","date":"2023-10-21T20:47:06.000Z","updated":"2023-10-21T21:51:34.591Z","comments":true,"path":"2023/10/21/My-Profile/","link":"","permalink":"http://example.com/2023/10/21/My-Profile/","excerpt":"","text":"PERSONAL Chaohui Guo/Male/1997 Ph.D. Candidate in Chatbots, Vrije University Amsterdam, 2027 Contact Phone Number：(+31) 686385352, (+86) 13563929132 Email：chaohui.guo.cn@gmail.com Wechat: guochaohui0210 EducationBachelor’s Degree: Qilu University of Technology, ‘_Big Data_’ (2015~2019)Master’s Degree: Beijing University of Technology, ‘_Q&amp;A System for Mental Health_’ (2020~2023)Doctor’s Degree: Vrije University Amsterdam, ‘_Chatbots for Mental Health_’ (2023~) Awards and Honors Awarded the First Prize of Shandong Province Software Design Competition 2017 Awarded the First Beijing University of Technology’s Prize Scholarship 2020-2021 Awarded the Outstanding Graduate Award 2021-2022 Awarded the First Tech Innovation Prize Scholarship 2022 Awarded the Excellent Tech Innovation Prize Scholarship 2022 Awarded the National Scholarship 2022 Awarded the Excellent Tech Innovation Prize Scholarship 2023 Awarded the Top 100 Graduate of Beijing University of Technology 2023 Awarded the Outstanding Graduate of Beijing 2023 Awarded the Outstanding Graduate of Beijing University of Technology 2023 Research papers: 1 SCI (Q2) paper, 1 SCI (Q4) paper, 1 EI paper and 1 Chinese paper Project Experiences In 2020, participate in the 14th Five-Year Plan of Informatization of the Disabled Persons’ Federation. From 2020 to 2021, participate in the closing work of the 2021 Overseas High-Level Talents Funding Scheme. In 2021, assisted my tutor in the preparation and holding of the “2021 China-Netherlands Smart City Academic Forum”. In 2021, assisted the tutor in guiding 2 undergraduates to complete the graduation project. From 2021 to 2022, participated in the planning of “Web3 + eye treatment Project”, “Web3 + digital pension Project”, and “campus epidemic prevention and Traceability System Project”. From 2021 to 2022, participated in the project team organized by the tutor to carry out the design and research of the “Campus Epidemic Prevention and Traceability System Project”. In 2022, an analysis of the interdisciplinary and team achievements at Beijing University of Technology. From 2021 to 2022, participate in the teaching assistant work, assist the tutor in the teaching preparation and implementation of the experimental course of “Cloud Service Engineering”, and assist the tutor in teaching the course “Introduction to Smart City”. ThanksThank you for taking the time to review my resume. I look forward to the opportunity to work with you!","categories":[],"tags":[{"name":"Self","slug":"Self","permalink":"http://example.com/tags/Self/"},{"name":"Introduction","slug":"Introduction","permalink":"http://example.com/tags/Introduction/"},{"name":"Contact","slug":"Contact","permalink":"http://example.com/tags/Contact/"}]}]